{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Dense,Layer,Input,Dropout,\n",
    "                                     BatchNormalization,Activation,\n",
    "                                     GRU,LSTM,GlobalMaxPool2D,Flatten,\n",
    "                                     GlobalAvgPool2D,GlobalMaxPool1D,Conv2D)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import LossCalculation\n",
    "import WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_word_embedding = 'path of your own word embedding results'\n",
    "word_embedding = np.load(path_word_embedding,allow_pickle=True)\n",
    "word_embedding = pd.DataFrame(word_embedding,columns=['Image_name','0','1','2','3','4','image_features','WordEmbedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 觀察圖像 features的分佈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "    plt.subplot(2,5,ii+1)\n",
    "    plt.imshow(word_embedding['image_features'][10][0][...,ii])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "    plt.subplot(2,5,ii+1)\n",
    "    plt.imshow(word_embedding['image_features'][100][0][...,ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ImageNamePath : 原始圖像路徑\n",
    "AllImage : 存放讀入的原始圖像\n",
    "\"\"\"\n",
    "pathFolder_modify = 'path of your images'\n",
    "x = os.listdir(pathFolder_modify)\n",
    "ImageNamePath = []\n",
    "for i in range(len(word_embedding)):\n",
    "    image_name = word_embedding['Image_name'][i]\n",
    "    pathImage = pathFolder_modify + image_name\n",
    "    ImageNamePath.append(pathImage)\n",
    "    \n",
    "    \n",
    "AllImage = []\n",
    "for i in range(len(ImageNamePath)):\n",
    "    img_path = ImageNamePath[i]\n",
    "    img = image.load_img(img_path,target_size=(224,224))\n",
    "    img = image.img_to_array(img)/255.0\n",
    "    img = img[5:200,5:200]\n",
    "    img = tf.image.resize(img,[227,227])\n",
    "    AllImage.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(AllImage[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen(df):\n",
    "    \"\"\"\n",
    "    生產更多組合資料\n",
    "    因為原始資料只有1833筆\n",
    "    所以隨機將兩筆資料配對\n",
    "    -->(case_1) 圖像features  + 對應的 wordEmbedding\n",
    "    --> (case_2)圖像features + 非對應的 wordEmbedding\n",
    "    \"\"\"\n",
    "    order=np.random.permutation(len(df))\n",
    "    for x in range(len(order)//2):\n",
    "        w_emb=df.iloc[order[2*x]][\"WordEmbedding\"]\n",
    "        idx=(np.random.rand()>0.5)*1\n",
    "        img = AllImage[order[2*x+idx]]\n",
    "        yield (w_emb,img),1.-idx\n",
    "        \n",
    "        \n",
    "def model_image():\n",
    "    \"\"\"\n",
    "    將原始圖像 進過 model_image進行 特徵提取\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(227,227,3))\n",
    "    x = Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # LRN layer\n",
    "    x = tf.nn.local_response_normalization(x, depth_radius=2, bias=2, alpha=1e-4, beta=0.75)\n",
    "\n",
    "    # second layer, convolution and pooling\n",
    "    x = Conv2D(filters=256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # LRN layer\n",
    "    x = tf.nn.local_response_normalization(x, depth_radius=2, bias=2, alpha=1e-4, beta=0.75)\n",
    "\n",
    "    # convolution layers\n",
    "    x = Conv2D(filters=384, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(filters=384, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Fully connection layer\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(128,activation='relu')(x)\n",
    "    embedding = Model(inputs=inputs, outputs=outputs,name='imageEmbbeding')\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def model_word():\n",
    "    \"\"\"\n",
    "    將bert結果 進過 model_word 特徵提取與圍堵調整\n",
    "    \"\"\"\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(5120,activation='tanh'))\n",
    "    seq.add(Dropout(0.25))\n",
    "    seq.add(Dense(1024,activation='tanh'))\n",
    "    seq.add(Dropout(0.25))\n",
    "    seq.add(Dense(128,activation='tanh'))\n",
    "    return seq\n",
    "\n",
    "\n",
    "\n",
    "class DistanceLayer(Layer):\n",
    "    def __int__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self,word,image):\n",
    "        distance = tf.reduce_sum(tf.square(word-image),-1)\n",
    "        return distance\n",
    "    \n",
    "    \n",
    "class SiameseModel(Model):\n",
    "    def __init__(self,siamese_network,margin = 0.25):\n",
    "        super(SiameseModel,self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name = 'loss')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "    \n",
    "    def train_step(self,data,label):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data,label)\n",
    "        gradients = tape.gradient(loss,self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients,self.siamese_network.trainable_weights))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {'loss':self.loss_tracker.result()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def test_step(self,data,label):\n",
    "        def accu(labels,predictions):\n",
    "            return K.mean((labels==1)==(predictions<0.05))\n",
    "        dist = self.siamese_network(data)\n",
    "        return accu(label,dist)\n",
    "\n",
    "    \n",
    "    def _compute_loss(self,data,label):\n",
    "        dist = self.siamese_network(data)\n",
    "        loss = K.mean(label * K.square(dist) + \\\n",
    "                      (1 - label) * K.square(K.maximum(self.margin - dist, 0.0)))\n",
    "        return loss\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切割訓練測試資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,val_df = train_test_split(word_embedding,test_size=0.2)\n",
    "\n",
    "train_dataloader = tf.data.Dataset.from_generator(partial(gen,train_df),\n",
    "                                                  output_types=((tf.float32,tf.float32),tf.float32)).\\\n",
    "                                                  prefetch(10).batch(32)\n",
    "\n",
    "val_dataloader = tf.data.Dataset.from_generator(partial(gen,val_df),\n",
    "                                                output_types=((tf.float32,tf.float32),tf.float32)).\\\n",
    "                                                prefetch(10).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embedding_image : model_image\n",
    "embedding_word : model_word\n",
    "\n",
    "siamese_network : 最後使用模型 ; \n",
    "input : [embedding_image結果,embedding_word結果] ,output: image & word latents distance \n",
    "\"\"\"\n",
    "\n",
    "embedding_image = model_image()\n",
    "embedding_word = model_word()\n",
    "\n",
    "\n",
    "word_input = Input(name='word',shape=(5120))\n",
    "image_input = Input(name='image',shape=(227,227,3))\n",
    "distances = DistanceLayer()(embedding_word(word_input),\n",
    "                            embedding_image(image_input))\n",
    "\n",
    "siamese_network = Model(inputs=[word_input,image_input],outputs=distances,name='final_model')\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "epochs = 100\n",
    "\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=optimizers.Adam(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session = tqdm(range(epochs))\n",
    "for e in session:\n",
    "    for x,y in train_dataloader:\n",
    "        loss = siamese_model.train_step(x,y)\n",
    "        session.set_postfix({\"loss\":loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = siamese_model.test_step(x_val,y_val)\n",
    "distance = siamese_model.siamese_network(x_val)\n",
    "model_training_loss = siamese_model.loss_tracker.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 利用直方圖統計 distance 分佈,原則越分開越好\n",
    "plt.hist(tf.concat(d,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "# 觀察圖像特徵學習情況,理論越離散越好\n",
    "plt.imshow(embedding_image(x_val[1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "# 觀察文字特徵學習情況,理論越離散越好\n",
    "plt.imshow(embedding_word(x_val[0]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save_weights('path of saving psuedo  siamese network')\n",
    "embedding_image.save_weights('path of saving image embedding model trained')\n",
    "embedding_word.save_weights('path of saving word embedding model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model's Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "呼叫 SiameseModel() class並存成一個新的變數\n",
    "利用 model.loads_weights 讀取訓練好的weights\n",
    "\"\"\"\n",
    "siamese_model2 = SiameseModel(siamese_network)\n",
    "siamese_model2.load_weights('path of saving psuedo  siamese network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model2.test_step(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
